{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: Giving opinion based on comment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data without using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('It was a decent read.. typical story line. Nothing unsavory as so many are. Just a slice of life, plausible.',\n",
       " 3.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) \n",
    "        reviews.append((review['reviewText'], review['overall']))\n",
    "reviews[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organising code with using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.score = score\n",
    "        self.text = text\n",
    "        self.sentiment = self.get_sentiment() # opinia\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: # score = 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "            \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        \n",
    "        \n",
    "#         print(negative[0].text)\n",
    "#         print(len(negative))\n",
    "#         print(len(positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_name = './Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall'])) # dodajemy obiekty klasy Review\n",
    "                       \n",
    "#print(reviews[6][1]) # if we do not use classes and we want to get to score ore text\n",
    "#reviews[6].sentiment\n",
    "reviews[6].sentiment\n",
    "# reviews[6].score\n",
    "# reviews[6].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size = 0.33, random_state =42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "# cont.evenly_distribute()\n",
    "\n",
    "# len(cont.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of Francine Rivers best series books!\n"
     ]
    }
   ],
   "source": [
    "print(training[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(reviews, test_size = 0.33, random_state =42)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.POSITIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_container.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bugs of word vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  like the couple in this story. I also really like the siblings in the story, I'm sure I want to know more about Jax. That said, I barely made it through. This book was 200 pages of bickering. I was invested in the couple and book 1 ends with a cliffhanger so of course I bought book 2. I have no plans to read 3.Both of these people have emotional intelligence issues. Seriously they act way younger than their age. He is the dominant rich man, but not really. She is the wonderful girl next door, but a nag. Blah.\n",
      "  (0, 8881)\t0.14099402382213577\n",
      "  (0, 8781)\t0.11467125845613337\n",
      "  (0, 8760)\t0.049115039148090844\n",
      "  (0, 8627)\t0.07896449958428199\n",
      "  (0, 8608)\t0.09061593543330497\n",
      "  (0, 8589)\t0.08893809387584807\n",
      "  (0, 8052)\t0.06819238770889387\n",
      "  (0, 8005)\t0.08106451053286465\n",
      "  (0, 7976)\t0.0703445486727966\n",
      "  (0, 7956)\t0.07351684604950251\n",
      "  (0, 7954)\t0.08994087061495956\n",
      "  (0, 7935)\t0.08555801779807404\n",
      "  (0, 7929)\t0.18818641202089786\n",
      "  (0, 7925)\t0.046647161805728546\n",
      "  (0, 7919)\t0.08704067953867456\n",
      "  (0, 7683)\t0.10778783529476611\n",
      "  (0, 7533)\t0.1099389250977345\n",
      "  (0, 7280)\t0.06000566806721127\n",
      "  (0, 7132)\t0.1528523646509871\n",
      "  (0, 7063)\t0.07482425472552111\n",
      "  (0, 7004)\t0.13871118195383292\n",
      "  (0, 6825)\t0.11743551072671095\n",
      "  (0, 6674)\t0.1616800942635406\n",
      "  (0, 6411)\t0.1395734751291837\n",
      "  (0, 6392)\t0.051053816965644636\n",
      "  :\t:\n",
      "  (0, 4174)\t0.167534517664317\n",
      "  (0, 4034)\t0.12913757303814513\n",
      "  (0, 3677)\t0.07406920604712733\n",
      "  (0, 3669)\t0.10680011336780142\n",
      "  (0, 3389)\t0.12052568185690977\n",
      "  (0, 2664)\t0.1266548316507125\n",
      "  (0, 2635)\t0.1434945941666175\n",
      "  (0, 2395)\t0.1528523646509871\n",
      "  (0, 2377)\t0.18572001776124017\n",
      "  (0, 1805)\t0.12280852372521264\n",
      "  (0, 1802)\t0.24561704745042529\n",
      "  (0, 1494)\t0.15689668205075605\n",
      "  (0, 1168)\t0.09584137014913575\n",
      "  (0, 1022)\t0.12807334634027193\n",
      "  (0, 1016)\t0.10403342284257237\n",
      "  (0, 991)\t0.11564754597200032\n",
      "  (0, 925)\t0.1750821821476792\n",
      "  (0, 885)\t0.18572001776124017\n",
      "  (0, 742)\t0.15689668205075605\n",
      "  (0, 423)\t0.033179728605603254\n",
      "  (0, 377)\t0.08555801779807404\n",
      "  (0, 292)\t0.1266548316507125\n",
      "  (0, 202)\t0.14625884643719506\n",
      "  (0, 149)\t0.06374333761468497\n",
      "  (0, 50)\t0.15689668205075605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# train_x_vector = vectorizer.fit_transform(train_x) # otrzymujemy ogromnÄ… macierz\n",
    "\n",
    "# we can do above in 2 steps, as below\n",
    "vectorizer.fit(train_x) # fit the model\n",
    "\n",
    "train_x_vectors = vectorizer.transform(train_x) # transform into vector\n",
    "test_x_vectors =vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[2])\n",
    "print(train_x_vectors[2])\n",
    "\n",
    "\n",
    "\n",
    "# TfidfVectorizer skip words like so, this, was, is etc. because they do not add any additional information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(kernel = 'linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_svm.predict\n",
    "\n",
    "test_x[2]\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "test_x[2]\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_gnb = MultinomialNB()\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6610576923076923\n",
      "0.8052884615384616\n",
      "0.7932692307692307\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y) )\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80582524, 0.80952381])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Scores (za duÅ¼o pozytywnych a za maÅ‚o negatywnych i neutralnych opinii)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "# f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "# f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "# f1_score(test_y, clf_gnb.predict(test_x_vectors), average=None, labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "\n",
    "# all models work good on positive comment but not very well on negative and neutral\n",
    "# as we distributed test values evenly the output is higher also for negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need to add another class which help to evenly distribute positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set  =['I enjoyed it, 5 stars', 'bad book, so not but', 'horrible, waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': (1, 4, 8, 16), 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': (1, 4, 8, 16)}\n",
    "\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv =5)\n",
    "clf.fit(train_x_vectors, train_y)\n",
    "\n",
    "# when ypu do not now what parameters to chose for a clasifier, use gridsearch wnd this function finds the best parameters values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving - pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have clasifier which we trained and do not want to train it one more time then we can save it\n",
    "import pickle\n",
    "\n",
    "with open('./Sci-kit-learn-first-Project.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Sci-kit-learn-first-Project.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_)\n",
    "loaded_clf.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
